{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGrMG008hmKU"
      },
      "source": [
        "# 2CS-SIL2/SIQ2 Lab04. Naïve Bayes\n",
        "\n",
        "<p style='text-align: right;font-style: italic;'>Designed by: Mr. Abdelkrime Aries</p>\n",
        "\n",
        "In this lab, we will learn about Naive Bayes by testing 2 implementations:\n",
        "- Multinomial Naïve Bayes\n",
        "- Gaussian Naïve Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2N1Sdr2hmKV"
      },
      "source": [
        "**Team:**\n",
        "- **Member 01**: Abdelkarim Bengherbia\n",
        "- **Member 02**: Mahdia Toubal\n",
        "- **Group**: SIL2/SIQ2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Y5wOszkMhmKW",
        "outputId": "04edc958-c377-4e9c-cd07-9f1352b6be2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "import sys, timeit\n",
        "from typing          import Tuple, List, Type\n",
        "from collections.abc import Callable\n",
        "\n",
        "sys.version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu_FILt_hmKW",
        "outputId": "5f6fb1f3-97ba-4483-bd90-420f64f1ebc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.0.2', '2.2.2', '3.10.0')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import numpy             as np\n",
        "import pandas            as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "\n",
        "np.__version__, pd.__version__, matplotlib.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Socn2pb3hmKW",
        "outputId": "de8a4f84-b966-47ec-f51f-3b822679cf87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.6.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "import sklearn\n",
        "\n",
        "from sklearn.naive_bayes   import CategoricalNB\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.metrics       import classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection         import train_test_split\n",
        "from sklearn.naive_bayes             import MultinomialNB, GaussianNB\n",
        "from sklearn.linear_model            import LogisticRegression\n",
        "from sklearn.tree                    import DecisionTreeClassifier\n",
        "from sklearn.metrics                 import precision_score, recall_score\n",
        "import timeit\n",
        "\n",
        "\n",
        "sklearn.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzvWX_ruhmKX"
      },
      "source": [
        "## I. Algorithms implementation\n",
        "\n",
        "In this section, we will try to implement multinomial Naive Bayes.\n",
        "\n",
        "\n",
        "**>> Try to use \"numpy\" which will save a lot of time and effort**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxT0AG1ehmKX",
        "outputId": "d5d4c1f1-91d7-446b-e569-a212dc32703d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Dataset play\n",
        "\n",
        "# outlook & temperature & humidity & windy\n",
        "Xplay = np.array([\n",
        "    ['sunny'   , 'hot' , 'high'  , 'no'],\n",
        "    ['sunny'   , 'hot' , 'high'  , 'yes'],\n",
        "    ['overcast', 'hot' , 'high'  , 'no'],\n",
        "    ['rainy'   , 'mild', 'high'  , 'no'],\n",
        "    ['rainy'   , 'cool', 'normal', 'no'],\n",
        "    ['rainy'   , 'cool', 'normal', 'yes'],\n",
        "    ['overcast', 'cool', 'normal', 'yes'],\n",
        "    ['sunny'   , 'mild', 'high'  , 'no'],\n",
        "    ['sunny'   , 'cool', 'normal', 'no'],\n",
        "    ['rainy'   , 'mild', 'normal', 'no'],\n",
        "    ['sunny'   , 'mild', 'normal', 'yes'],\n",
        "    ['overcast', 'mild', 'high'  , 'yes'],\n",
        "    ['overcast', 'hot' , 'normal', 'no'],\n",
        "    ['rainy'   , 'mild', 'high'  , 'yes']\n",
        "])\n",
        "\n",
        "Yplay = np.array([\n",
        "    'no',\n",
        "    'no',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'no',\n",
        "    'yes',\n",
        "    'no',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'yes',\n",
        "    'no'\n",
        "])\n",
        "\n",
        "len(Xplay), len(Yplay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RnQNZrBhmKX",
        "outputId": "a9e4d8e9-170c-48c8-bc7c-8e428af88e24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# height & weight & footsize & person\n",
        "Xperson = np.array([\n",
        "    [182., 81.6, 30.],\n",
        "    [180., 86.2, 28.],\n",
        "    [170., 77.1, 30.],\n",
        "    [180., 74.8, 25.],\n",
        "    [152., 45.4, 15.],\n",
        "    [168., 68.0, 20.],\n",
        "    [165., 59.0, 18.],\n",
        "    [175., 68.0, 23.]\n",
        "])\n",
        "\n",
        "Yperson = np.array([\n",
        "    'male', 'male', 'male', 'male',\n",
        "    'female', 'female', 'female', 'female'\n",
        "])\n",
        "\n",
        "len(Xperson), len(Yperson)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-WlaJhRhmKY"
      },
      "source": [
        "### I.1. Prior statistics\n",
        "\n",
        "Given an output list $Y[M]$, the probability of each class $c$ is estimated as:\n",
        "$$p(c) = \\frac{\\#(Y = c)}{|Y|}$$\n",
        "\n",
        "In here, we want to store the frequencies of different classes.\n",
        "Our function must return two lists:\n",
        "- One containing the names of unique classes.\n",
        "- Another containing their frequencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C8IZr5qhmKZ",
        "outputId": "55e0d7d6-9bca-4ae6-9b73-2357f31c0907"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array(['no', 'yes'], dtype='<U3'), array([5, 9])),\n",
              " (array(['female', 'male'], dtype='<U6'), array([4, 4])))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# TODO: Prior statistics\n",
        "def fit_prior(Y: 'np.ndarray[M](str)') -> Tuple['np.ndarray[K](str)', 'np.ndarray[K](int)']:\n",
        "    # Get unique classes and their counts\n",
        "    classes, counts = np.unique(Y, return_counts=True)\n",
        "    return classes, counts\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# ((array(['no', 'yes'], dtype='<U3'), array([5, 9])),\n",
        "#  (array(['female', 'male'], dtype='<U6'), array([4, 4])))\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "fit_prior(Yplay), fit_prior(Yperson)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su1cLnXThmKZ"
      },
      "source": [
        "### I.2. Multinomial Law\n",
        "\n",
        "In this section, we will implement multinomial naive Bayes from scratch using Numpy.\n",
        "\n",
        "#### I.2.1. Multinomial Likelihood statistics\n",
        "\n",
        "Given:\n",
        "- $A$: a categorical feature\n",
        "- $Y$: the ouput\n",
        "- $C$: the classes\n",
        "\n",
        "The function takes as argument $A, Y, C$ previously described.\n",
        "It must return:\n",
        "- $V$: unique values of this feature (feature's categories)\n",
        "- $S[|C|, |V|]$: a matrix containing count $\\#(Y = c \\wedge A = v),\\, \\forall c \\in C, \\forall v \\in A$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzubrLJPhmKa",
        "outputId": "7e256853-5fc0-476a-8d45-8ad988967c80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array(['overcast', 'rainy', 'sunny'], dtype='<U8'),\n",
              "  array([[0, 2, 3],\n",
              "         [4, 3, 2]])),\n",
              " (array(['cool', 'hot', 'mild'], dtype='<U8'),\n",
              "  array([[1, 2, 2],\n",
              "         [3, 2, 4]])))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# TODO: Multinomial Likelihood statistics\n",
        "def fit_multinomial_likelihood(A: 'np.ndarray[M](str)',\n",
        "                               Y: 'np.ndarray[M](str)',\n",
        "                               C: 'np.ndarray[C](str)') -> Tuple['np.ndarray[V](str)', 'np.ndarray[C, V](int)']:\n",
        "    # Get unique values of the feature\n",
        "    V = np.unique(A)\n",
        "\n",
        "    # Initialize the statistics matrix\n",
        "    S = np.zeros((len(C), len(V)), dtype=int)\n",
        "\n",
        "    # Fill the statistics matrix\n",
        "    for c_idx, c in enumerate(C):\n",
        "        for v_idx, v in enumerate(V):\n",
        "            # Count occurrences where Y = c and A = v\n",
        "            S[c_idx, v_idx] = np.sum((Y == c) & (A == v))\n",
        "\n",
        "    return V, S\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# ((array(['overcast', 'rainy', 'sunny'], dtype='<U8'),\n",
        "#   array([[0, 2, 3],\n",
        "#          [4, 3, 2]])),\n",
        "#  (array(['cool', 'hot', 'mild'], dtype='<U8'),\n",
        "#   array([[1, 2, 2],\n",
        "#          [3, 2, 4]])))\n",
        "#---------------------------------------------------------------------\n",
        "C_t = np.array(['no', 'yes'])\n",
        "fit_multinomial_likelihood(Xplay[:, 0], Yplay, C_t), fit_multinomial_likelihood(Xplay[:, 1], Yplay, C_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywyOk4rbhmKa"
      },
      "source": [
        "#### I.2.2. Multinomial Likelihood training\n",
        "\n",
        "**Nothing to code here, although you have to know how it functions for next use**\n",
        "\n",
        "This function aims to generate parameters $\\theta$.\n",
        "In our case, paramters are diffrent from those of *logistic regrssion*.\n",
        "They are a dictionary (map) with two entries:\n",
        "- \"prior\": a dictionary having \"vocab\" a list of values and \"freq\" a list of their respective frequencies.\n",
        "- \"likelihood\": a list of dictionaries representing statistics of each feature (the same order of $X$ features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq27MeP_hmKa",
        "outputId": "e6001392-0e9b-443a-c9d2-156897e8fd04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prior': {'vocab': array(['no', 'yes'], dtype='<U3'), 'freq': array([5, 9])},\n",
              " 'likelihood': [{'vocab': array(['overcast', 'rainy', 'sunny'], dtype='<U8'),\n",
              "   'freq': array([[0, 2, 3],\n",
              "          [4, 3, 2]])},\n",
              "  {'vocab': array(['cool', 'hot', 'mild'], dtype='<U8'),\n",
              "   'freq': array([[1, 2, 2],\n",
              "          [3, 2, 4]])},\n",
              "  {'vocab': array(['high', 'normal'], dtype='<U8'),\n",
              "   'freq': array([[4, 1],\n",
              "          [3, 6]])},\n",
              "  {'vocab': array(['no', 'yes'], dtype='<U8'),\n",
              "   'freq': array([[2, 3],\n",
              "          [6, 3]])}]}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "def fit_multinomial_NB(X: 'np.ndarray[M, N](str)',\n",
        "                       Y: 'np.ndarray[M](str)'\n",
        "                       ) -> object:\n",
        "\n",
        "    Theta   = {'prior': {}, 'likelihood': []}\n",
        "\n",
        "    Theta['prior']['vocab'], Theta['prior']['freq'] = fit_prior(Y)\n",
        "\n",
        "    for j in range(X.shape[1]):\n",
        "        likelihood = {}\n",
        "        likelihood['vocab'], likelihood['freq'] = fit_multinomial_likelihood(X[:, j], Y, Theta['prior']['vocab'])\n",
        "        Theta['likelihood'].append(likelihood)\n",
        "\n",
        "    return Theta\n",
        "\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# {'prior': {'vocab': array(['no', 'yes'], dtype='<U3'), 'freq': array([5, 9])},\n",
        "#  'likelihood': [{'vocab': array(['overcast', 'rainy', 'sunny'], dtype='<U8'),\n",
        "#    'freq': array([[0, 2, 3],\n",
        "#           [4, 3, 2]])},\n",
        "#   {'vocab': array(['cool', 'hot', 'mild'], dtype='<U8'),\n",
        "#    'freq': array([[1, 2, 2],\n",
        "#           [3, 2, 4]])},\n",
        "#   {'vocab': array(['high', 'normal'], dtype='<U8'),\n",
        "#    'freq': array([[4, 1],\n",
        "#           [3, 6]])},\n",
        "#   {'vocab': array(['no', 'yes'], dtype='<U8'),\n",
        "#    'freq': array([[2, 3],\n",
        "#           [6, 3]])}]}\n",
        "#---------------------------------------------------------------------\n",
        "Theta_play = fit_multinomial_NB(Xplay, Yplay)\n",
        "\n",
        "Theta_play"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fNMJXuVhmKa"
      },
      "source": [
        "#### I.2.3. Multinomial Likelihood prediction\n",
        "\n",
        "Given:\n",
        "- $A$: a categorical feature\n",
        "- $V$: unique values of this feature (feature's categories)\n",
        "- $Y$: the ouput\n",
        "- $C$: the classes\n",
        "- $\\alpha$: smoothing factor\n",
        "\n",
        "Log likelihood is calculated as:\n",
        "$$ \\log p(A=v|Y=c) = \\log(\\#(Y = k \\wedge A = v) + \\alpha) - \\log(\\#(y = k) + \\alpha * |V|)$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHYEFSnShmKa",
        "outputId": "c32982b5-e220-4a81-80d8-19d8cc33002f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.int64(1), -1)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# You can use this function in the next implimentation\n",
        "# It takes a list of unique values V and a given value v\n",
        "# It returns the position of v in V\n",
        "# If v does not exist in V, it rturns -1\n",
        "def find_idx(V: np.ndarray, v: str) -> int:\n",
        "    k = np.argwhere(V == v).flatten()\n",
        "    if len(k):\n",
        "        return k[0]\n",
        "    return -1\n",
        "\n",
        "V_t = np.array(['One', 'Two', 'Three'])\n",
        "find_idx(V_t, 'Two'), find_idx(V_t, 'Four')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y82EfP2fhmKb",
        "outputId": "bf607a29-0563-4cc3-a9ff-dea45d22e486"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.91629073, -1.09861229]), array([-2.07944154, -2.48490665]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# TODO: Multinomial Likelihood prediction\n",
        "def predict_multinomial_NB1(v: str,\n",
        "                           j: int,\n",
        "                           Theta: object,\n",
        "                           alpha: float = 0.) -> 'np.ndarray[C](float)':\n",
        "    # Get classes, feature values, and frequencies\n",
        "    classes = Theta['prior']['vocab']\n",
        "    feature_values = Theta['likelihood'][j]['vocab']\n",
        "    frequencies = Theta['likelihood'][j]['freq']\n",
        "    class_counts = Theta['prior']['freq']\n",
        "\n",
        "    # Initialize log probabilities\n",
        "    log_probs = np.zeros(len(classes))\n",
        "\n",
        "    # Find index of the value in the feature values\n",
        "    v_idx = find_idx(feature_values, v)\n",
        "\n",
        "    # Calculate log probabilities for each class\n",
        "    for c_idx, c in enumerate(classes):\n",
        "        if v_idx != -1:  # Value exists in training data\n",
        "            numerator = frequencies[c_idx, v_idx] + alpha\n",
        "        else:  # Value doesn't exist in training data\n",
        "            numerator = alpha\n",
        "\n",
        "        denominator = class_counts[c_idx] + alpha * len(feature_values)\n",
        "\n",
        "        # Calculate log probability\n",
        "        if denominator > 0:  # Avoid division by zero\n",
        "            log_probs[c_idx] = np.log(numerator) - np.log(denominator)\n",
        "        else:\n",
        "            log_probs[c_idx] = -np.inf\n",
        "\n",
        "    return log_probs\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# (array([-0.91629073, -1.09861229]), array([-2.07944154, -2.48490665]))\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "X_t = np.array([\n",
        "    ['rainy', 'cool', 'normal', 'yes'],\n",
        "    ['snowy', 'cool', 'normal', 'yes'],\n",
        "    ['sunny', 'hot' , 'normal', 'no']\n",
        "])\n",
        "\n",
        "predict_multinomial_NB1('rainy', 0, Theta_play, alpha=0.), \\\n",
        "    predict_multinomial_NB1('snowy', 0, Theta_play, alpha=1.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwlMh736hmKb"
      },
      "source": [
        "### I.3. Normal (Gaussian) Law\n",
        "\n",
        "In this section, we will implement gaussian naive Bayes from scratch using Numpy.\n",
        "\n",
        "#### I.3.1. Gaussian Likelihood statistics\n",
        "\n",
        "Given:\n",
        "- $A$: a categorical feature\n",
        "- $Y$: the ouput\n",
        "- $C$: the classes\n",
        "\n",
        "The function takes as argument $A, Y, C$ previously described.\n",
        "It must return $S[|C|, 2, N]$; a tensor having these dimensions:\n",
        "- first dimension: each element represents one class's statistics\n",
        "- second dimension: 1st element represents means; 2ns element represents variances\n",
        "- third dimension: each element represents mean/variance of the respective feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-QwQ_rAhmKb",
        "outputId": "3470dbc5-f70c-4a0a-a94d-6c2497ca77be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[165.        ,  60.1       ,  19.        ],\n",
              "        [ 92.66666667, 114.04      ,  11.33333333]],\n",
              "\n",
              "       [[178.        ,  79.925     ,  28.25      ],\n",
              "        [ 29.33333333,  25.47583333,   5.58333333]]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# TODO: Gaussian Likelihood statistics\n",
        "def fit_gaussian_likelihood(X: 'np.ndarray[M](float)',\n",
        "                            Y: 'np.ndarray[M](str)',\n",
        "                            C: 'np.ndarray[C](str)') -> Tuple['np.ndarray[C, 2, N](float)']:\n",
        "    # Get the number of features\n",
        "    n_features = X.shape[1] if len(X.shape) > 1 else 1\n",
        "\n",
        "    # Initialize the tensor to store means and variances\n",
        "    S = np.zeros((len(C), 2, n_features))\n",
        "\n",
        "    # For each class, calculate mean and variance of each feature\n",
        "    for c_idx, c in enumerate(C):\n",
        "        # Get samples belonging to class c\n",
        "        X_c = X[Y == c]\n",
        "\n",
        "        if len(X_c) > 0:\n",
        "            # Calculate mean for each feature\n",
        "            S[c_idx, 0, :] = np.mean(X_c, axis=0)\n",
        "            # Calculate variance for each feature\n",
        "            S[c_idx, 1, :] = np.var(X_c, axis=0, ddof=1)  # Use ddof=1 for unbiased estimation\n",
        "\n",
        "    return S\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# array([[[165.        ,  60.1       ,  19.        ],\n",
        "#         [ 92.66666667, 114.04      ,  11.33333333]],\n",
        "\n",
        "#        [[178.        ,  79.925     ,  28.25      ],\n",
        "#         [ 29.33333333,  25.47583333,   5.58333333]]])\n",
        "#---------------------------------------------------------------------\n",
        "C_t = np.array(['female', 'male'])\n",
        "fit_gaussian_likelihood(Xperson, Yperson, C_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tKyT60GhmKb"
      },
      "source": [
        "#### I.3.2. Gaussian Likelihood training\n",
        "\n",
        "**Nothing to code here, although you have to know how it functions for next use**\n",
        "\n",
        "This function aims to generate parameters $\\theta$.\n",
        "In our case, paramters are diffrent from those of *logistic regrssion*.\n",
        "They are a dictionary (map) with two entries:\n",
        "- \"prior\": a dictionary having \"vocab\" a list of values and \"freq\" a list of their respective frequencies.\n",
        "- \"likelihood\": a tensor of shape $[|C|, 2, N]$ containing likelihood statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsciHc2EhmKb",
        "outputId": "cce5c3a4-b8ea-4e58-e201-1c62c0004df6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prior': {'vocab': array(['female', 'male'], dtype='<U6'),\n",
              "  'freq': array([4, 4])},\n",
              " 'likelihood': array([[[165.        ,  60.1       ,  19.        ],\n",
              "         [ 92.66666667, 114.04      ,  11.33333333]],\n",
              " \n",
              "        [[178.        ,  79.925     ,  28.25      ],\n",
              "         [ 29.33333333,  25.47583333,   5.58333333]]])}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "def fit_gaussian_NB(X: 'np.ndarray[M, N](str)',\n",
        "                    Y: 'np.ndarray[M](str)'\n",
        "                    ) -> object:\n",
        "\n",
        "    Theta   = {'prior': {}, 'likelihood': []}\n",
        "\n",
        "    Theta['prior']['vocab'], Theta['prior']['freq'] = fit_prior(Y)\n",
        "    Theta['likelihood'] = fit_gaussian_likelihood(X, Y, Theta['prior']['vocab'])\n",
        "\n",
        "    return Theta\n",
        "\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# {'prior': {'vocab': array(['female', 'male'], dtype='<U6'),\n",
        "#   'freq': array([4, 4])},\n",
        "#  'likelihood': array([[[165.        ,  60.1       ,  19.        ],\n",
        "#          [ 92.66666667, 114.04      ,  11.33333333]],\n",
        "\n",
        "#         [[178.        ,  79.925     ,  28.25      ],\n",
        "#          [ 29.33333333,  25.47583333,   5.58333333]]])}\n",
        "#---------------------------------------------------------------------\n",
        "Theta_person = fit_gaussian_NB(Xperson, Yperson)\n",
        "\n",
        "Theta_person"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxPAErHdhmKb"
      },
      "source": [
        "#### I.2.4. Gaussian Likelihood prediction\n",
        "\n",
        "Given:\n",
        "- $A$: a numerical feature\n",
        "- $\\mu_{Ac}$: mean of values of feature $A$ having $c$ as class\n",
        "- $\\sigma_{Ac}$: variance of values of feature $A$ having $c$ as class\n",
        "- $Y$: the output\n",
        "- $C$: the classes\n",
        "\n",
        "Log likelihood is calculated as:\n",
        "$$ \\log p(A=v|Y=c) = \\frac{-(v-\\mu_{Ac})^2}{2 \\sigma_{Ac}^2} - \\log(\\sqrt{2\\pi \\sigma_{Ac}^2})$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nAMjmgKhmKb",
        "outputId": "f0a5b0b5-7513-4563-9319-afbdf06574a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-4.93164438, -3.03443716]), array([0.00721463, 0.04810173]))"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# TODO: Gaussian Likelihood prediction\n",
        "def predict_gaussian_NB1(v: str,\n",
        "                         j: int,\n",
        "                         Theta: object,\n",
        "                         alpha: float = 0.  # this is just added for compatibility\n",
        "                        ) -> 'np.ndarray[C](float)':\n",
        "    # Get classes\n",
        "    classes = Theta['prior']['vocab']\n",
        "\n",
        "    # Convert v to float if it's a string\n",
        "    v = float(v)\n",
        "\n",
        "    # Initialize log probabilities\n",
        "    log_probs = np.zeros(len(classes))\n",
        "\n",
        "    # For each class, calculate Gaussian log probability\n",
        "    for c_idx, c in enumerate(classes):\n",
        "        # Get mean and variance\n",
        "        mean = Theta['likelihood'][c_idx, 0, j]\n",
        "        var = Theta['likelihood'][c_idx, 1, j]\n",
        "\n",
        "        # Avoid division by zero\n",
        "        if var > 0:\n",
        "            # Calculate log probability using Gaussian PDF formula\n",
        "            log_probs[c_idx] = -((v - mean) ** 2) / (2 * var) - np.log(np.sqrt(2 * np.pi * var))\n",
        "        else:\n",
        "            # If variance is zero, assign a very low probability\n",
        "            log_probs[c_idx] = -np.inf\n",
        "\n",
        "    return log_probs\n",
        "\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# (array([-4.93164438, -3.03443716]), array([0.00721463, 0.04810173]))\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "pp = predict_gaussian_NB1(183, 0, Theta_person)\n",
        "\n",
        "pp, np.exp(pp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-X-3mV7hmKb"
      },
      "source": [
        "### I.4. Final prediction\n",
        "\n",
        "Our goal is to calculate approximate log probabilities of all classes given a sample:\n",
        "$$\\log P(y=c_k | \\overrightarrow{x} = \\overrightarrow{f})  \\approx \\log P(y=c_k) + \\sum\\limits_{f_j \\in \\overrightarrow{f}} \\log P(f_j = x_j|y=c_k)$$\n",
        "\n",
        "This function takes:\n",
        "- $X^{(i)}$ one sample with $N$ features\n",
        "- $\\theta$ parameters (either those of multinomial or gaussian)\n",
        "- $pred_{fct}$ a function to predict one feauture (either multinomial or gaussian)\n",
        "- add_prior: if True, add prior probability\n",
        "- $\\alpha$ smoothing factor (passing it to gaussian function will do nothing)\n",
        "\n",
        "It must return a vector of probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o63hHRcFhmKb",
        "outputId": "bb2ce054-eb54-4068-e935-bc93fca29bfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-3.59617006, -4.95406494]),\n",
              " array([-2.56655064, -4.51223219]),\n",
              " array([-2.85774653, -4.23617476]),\n",
              " array([-10.401093  , -22.03977023]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# TODO: Final prediction\n",
        "def predict_NB1(Xi: 'np.ndarray[N]',\n",
        "                Theta: object,\n",
        "                pred_fct: Callable,\n",
        "                add_prior: bool = True,\n",
        "                alpha: float = 1.0\n",
        "               ) -> 'np.ndarray[C](float)':\n",
        "    # Get classes\n",
        "    classes = Theta['prior']['vocab']\n",
        "\n",
        "    # Initialize log probabilities with zeros\n",
        "    log_probs = np.zeros(len(classes))\n",
        "\n",
        "    # Add log prior probabilities if requested\n",
        "    if add_prior:\n",
        "        class_counts = Theta['prior']['freq']\n",
        "        total_count = np.sum(class_counts)\n",
        "        for c_idx, c in enumerate(classes):\n",
        "            log_probs[c_idx] += np.log(class_counts[c_idx] / total_count)\n",
        "\n",
        "    # Add log likelihood for each feature\n",
        "    for j in range(len(Xi)):\n",
        "        feature_log_probs = pred_fct(Xi[j], j, Theta, alpha)\n",
        "        log_probs += feature_log_probs\n",
        "\n",
        "    return log_probs\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# (array([-2.20940778, -3.86937505]),\n",
        "#  array([-2.56655064, -4.51223219]),\n",
        "#  array([-2.85774653, -4.23617476]),\n",
        "#  array([-10.401093  , -22.03977023]))\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "X_t1 = np.array(['sunny', 'hot' , 'high', 'no'])\n",
        "X_t2 = np.array([183., 59., 20.])\n",
        "\n",
        "predict_NB1(X_t1, Theta_play, predict_multinomial_NB1, add_prior=True, alpha=0.0), \\\n",
        "predict_NB1(X_t1, Theta_play, predict_multinomial_NB1, add_prior=False, alpha=0.0), \\\n",
        "predict_NB1(X_t1, Theta_play, predict_multinomial_NB1, add_prior=False, alpha=1.0), \\\n",
        "predict_NB1(X_t2, Theta_person, predict_gaussian_NB1, add_prior=False),"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIh7TSRJhmKb"
      },
      "source": [
        "### I.5. Final product\n",
        "\n",
        "**>> Nothing to code here**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4NVN4ywhmKb",
        "outputId": "4092d3af-ada8-452b-e5dd-0b9099bfabe9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['yes', 'yes', 'no'], dtype='<U3'),\n",
              " array([[-5.20912179, -4.10264337],\n",
              "        [-6.30773408, -5.48893773],\n",
              "        [-3.88736595, -4.67800751]]),\n",
              " array(['female', 'male'], dtype='<U6'),\n",
              " array([[-11.09424018, -22.73291741],\n",
              "        [-15.27968966, -12.41764665]]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "class NaiveBayes(object):\n",
        "\n",
        "    def __init__(self, multinomial=True):\n",
        "        if multinomial:\n",
        "            self.train = fit_multinomial_NB\n",
        "            self.pred = predict_multinomial_NB1\n",
        "        else:\n",
        "            self.train = fit_gaussian_NB\n",
        "            self.pred = predict_gaussian_NB1\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        self.Theta = self.train(X, Y)\n",
        "\n",
        "    def predict(self, X, add_prior=True, prob=False, alpha=0.):\n",
        "        Y_pred = []\n",
        "        for i in range(len(X)):\n",
        "            Y_pred.append(predict_NB1(\n",
        "                X[i,:], self.Theta, self.pred, add_prior=add_prior, alpha=alpha\n",
        "                ))\n",
        "\n",
        "        Y_pred = np.array(Y_pred)\n",
        "\n",
        "        if prob:\n",
        "            return Y_pred\n",
        "\n",
        "        return np.choose(np.argmax(Y_pred, axis=1), self.Theta['prior']['vocab'])\n",
        "\n",
        "#=====================================================================\n",
        "# UNIT TEST\n",
        "#=====================================================================\n",
        "# Result:\n",
        "# (array(['yes', 'yes', 'no'], dtype='<U3'),\n",
        "#  array([[-3.82235951, -3.01795347],\n",
        "#         [-4.9209718 , -4.40424783],\n",
        "#         [-2.50060367, -3.59331761]]),\n",
        "#  array(['female', 'male'], dtype='<U6'),\n",
        "#  array([[ -9.901093  , -21.53977023],\n",
        "#         [-14.08654248, -11.22449947]]))\n",
        "#---------------------------------------------------------------------\n",
        "\n",
        "multinomial_nb = NaiveBayes()\n",
        "multinomial_nb.fit(Xplay, Yplay)\n",
        "\n",
        "gaussian_nb = NaiveBayes(multinomial=False)\n",
        "gaussian_nb.fit(Xperson, Yperson)\n",
        "\n",
        "X_t1 = np.array([\n",
        "    ['rainy', 'cool', 'normal', 'yes'],\n",
        "    ['snowy', 'cool', 'normal', 'yes'],\n",
        "    ['sunny', 'hot' , 'high', 'no']\n",
        "])\n",
        "\n",
        "X_t2 = np.array([\n",
        "    [183., 59., 20.],\n",
        "    [175., 65., 30.]\n",
        "])\n",
        "\n",
        "\n",
        "multinomial_nb.predict(X_t1, alpha=1.), \\\n",
        "    multinomial_nb.predict(X_t1, alpha=1., prob=True), \\\n",
        "    gaussian_nb.predict(X_t2), \\\n",
        "    gaussian_nb.predict(X_t2, prob=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zIm_V8chmKb"
      },
      "source": [
        "## II. Application and Analysis\n",
        "\n",
        "In this section, we will test different concepts by running an experiment, formulating a hypothesis and trying to justify it.\n",
        "\n",
        "### II.1. Prior probability\n",
        "\n",
        "We want to test the effect of prior probability.\n",
        "To do this, we trained two models:\n",
        "1. With prior probability\n",
        "1. Without prior probability (It considers a uniform distribution of classes)\n",
        "\n",
        "To test whether the models have adapted well to the training dataset, we will test them on the same dataset and calculate the classification ratio.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHyVJLBOhmKc",
        "outputId": "7ebd1717-726b-42e5-9839-5973d849c829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Considring prior probability\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       1.00      0.80      0.89         5\n",
            "         yes       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n",
            "No prior probability\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       0.67      0.80      0.73         5\n",
            "         yes       0.88      0.78      0.82         9\n",
            "\n",
            "    accuracy                           0.79        14\n",
            "   macro avg       0.77      0.79      0.78        14\n",
            "weighted avg       0.80      0.79      0.79        14\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nb_withPrior     = CategoricalNB(alpha=1.0, fit_prior=True )\n",
        "nb_noPrior       = CategoricalNB(alpha=1.0, fit_prior=False)\n",
        "\n",
        "enc         = OrdinalEncoder()\n",
        "Xplay_tf    = enc.fit_transform(Xplay)\n",
        "nb_withPrior.fit(Xplay_tf, Yplay)\n",
        "nb_noPrior.fit(Xplay_tf, Yplay)\n",
        "\n",
        "Ypred_withPrior = nb_withPrior.predict(Xplay_tf)\n",
        "Ypred_noPrior = nb_noPrior.predict(Xplay_tf)\n",
        "\n",
        "\n",
        "print( 'Considring prior probability'  )\n",
        "print(classification_report(Yplay, Ypred_withPrior))\n",
        "\n",
        "print( 'No prior probability'  )\n",
        "print(classification_report(Yplay, Ypred_noPrior))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oapm_FYHhmKc"
      },
      "source": [
        "**TODO: Analyze the results**\n",
        "\n",
        "1. What do you notice, indicating if prior probability is useful in this case?\n",
        "1. How does this probability affect the outcome?\n",
        "1. When are we sure that using this probability is unnecessary?\n",
        "\n",
        "**Answer**\n",
        "\n",
        "1. I notice that using prior probability improves the model's accuracy from 79% to 93%. Both precision and recall are higher for both classes when prior probability is used. The F1-score also improves from 0.78 to 0.92 on average.\n",
        "1. Prior probability affects the outcome by biasing the classification toward the most common class. In this dataset, there are more \"yes\" examples (9) than \"no\" examples (5). When we use prior probability, the model takes this class imbalance into account and is more likely to predict \"yes\" when the evidence from features is ambiguous. This is mathematically represented by adding the log prior probability to the sum of log likelihoods.\n",
        "1. Using prior probability is unnecessary when:\n",
        "\n",
        "- Classes are perfectly balanced (equal number of examples for each class)\n",
        "- We specifically want to ignore class distribution (perhaps for ethical reasons or when we know the test data has a different distribution)\n",
        "- The likelihood signals are very strong, making the prior contribution negligible in the final decision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jecaTB2ahmKc"
      },
      "source": [
        "### II.2. Smoothing\n",
        "\n",
        "We want to test the Lidstone smoothing's effect.\n",
        "To do this, we trained three models:\n",
        "1. alpha = 1 (Laplace smoothing)\n",
        "1. alpha = 0.5\n",
        "1. alpha = 0 (without smoothing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOX0ZJZfhmKd",
        "outputId": "9eef0496-fbe1-4201-95d5-b0284bd7ec1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha = 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       1.00      0.80      0.89         5\n",
            "         yes       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n",
            "Alpha = 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       1.00      0.80      0.89         5\n",
            "         yes       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n",
            "Alpha = 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       1.00      0.80      0.89         5\n",
            "         yes       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.93        14\n",
            "   macro avg       0.95      0.90      0.92        14\n",
            "weighted avg       0.94      0.93      0.93        14\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/naive_bayes.py:1528: RuntimeWarning: divide by zero encountered in log\n",
            "  np.log(smoothed_cat_count) - np.log(smoothed_class_count.reshape(-1, 1))\n"
          ]
        }
      ],
      "source": [
        "NBC_10 = CategoricalNB(alpha = 1.0 )\n",
        "NBC_05 = CategoricalNB(alpha = 0.5 )\n",
        "NBC_00 = CategoricalNB(alpha = 0.0 )\n",
        "\n",
        "NBC_10.fit( Xplay_tf,   Yplay )\n",
        "NBC_05.fit( Xplay_tf,   Yplay )\n",
        "NBC_00.fit( Xplay_tf,   Yplay )\n",
        "\n",
        "Y_10   = NBC_10.predict(Xplay_tf)\n",
        "Y_05   = NBC_05.predict(Xplay_tf)\n",
        "Y_00   = NBC_00.predict(Xplay_tf)\n",
        "\n",
        "\n",
        "print(                'Alpha = 1.0'                        )\n",
        "print(classification_report(Yplay, Y_10, zero_division=0.0))\n",
        "\n",
        "print(                'Alpha = 0.5'                        )\n",
        "print(classification_report(Yplay, Y_05, zero_division=0.0))\n",
        "\n",
        "print(                'Alpha = 0.0'                        )\n",
        "print(classification_report(Yplay, Y_00, zero_division=0.0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiH9DkAFhmKe"
      },
      "source": [
        "**TODO: Analyze the results**\n",
        "\n",
        "1. What do you notice, indicating if smoothing affects performance in this case?\n",
        "1. Based on the past answeer, Why?\n",
        "1. Why do we get a \"RuntimeWarning: divide by zero\" error?\n",
        "1. What is the benefit of smoothing (generally; not just for this case)?\n",
        "\n",
        "**Answer**\n",
        "\n",
        "1. Interestingly, smoothing doesn't affect the performance in this specific case. All three models (with alpha = 1.0, 0.5, and 0.0) show identical performance metrics.\n",
        "1. This is likely because the dataset doesn't have many zero count features that need smoothing. All feature class combinations that appear in the test data probably also appear in the training data with non-zero counts. Additionally, the dataset is very small, so the specific instances being tested might not require smoothing to be correctly classified.\n",
        "1. We get the \"RuntimeWarning: divide by zero\" error when alpha = 0.0 because without smoothing, some feature class combinations have zero count. When calculating log probabilities, log(0) is undefined and causes the error. However, this error occurs during internal calculations and doesn't affect the final predictions in this specific case.\n",
        "1. The benefits of smoothing generally include:\n",
        "\n",
        "- Preventing zero probabilities that would make the entire product zero (the \"zero probability problem\")\n",
        "- Handling unseen features in test data\n",
        "- Reducing overfitting by adding a \"prior\" belief that all feature values are possible\n",
        "- Making the model more robust to rare events\n",
        "- Enabling the model to generalize better to new data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyrcKsxJhmKf"
      },
      "source": [
        "### II.3. Naive Bayes performance\n",
        "\n",
        "Naive Bayes is known to generate powerful models when it comes to classifying textual documents.\n",
        "We want to test this proposition using spam detection over [SMS Spam Collection Dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset) dataset.\n",
        "\n",
        "Each message is represented using term frequency (TF), where a word is considered as a feature.\n",
        "In this case, a message is represented by a vector of frequencies (how many times each word appeared in the message).\n",
        "We want to compare these models:\n",
        "1. Multinomial Naive Bayes (MNB)\n",
        "1. Gaussian Naive Bayes (GNB)\n",
        "1. Logistic Regression (LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ga5-TG8-hmKf",
        "outputId": "17fdefb4-2c56-4ce5-ae7f-f82f6e27b156"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text class\n",
              "0  Go until jurong point, crazy.. Available only ...   ham\n",
              "1                      Ok lar... Joking wif u oni...   ham\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
              "3  U dun say so early hor... U c already then say...   ham\n",
              "4  Nah I don't think he goes to usf, he lives aro...   ham"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3e5014b-e8c7-409b-b3d4-bc93d1a26881\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3e5014b-e8c7-409b-b3d4-bc93d1a26881')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c3e5014b-e8c7-409b-b3d4-bc93d1a26881 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c3e5014b-e8c7-409b-b3d4-bc93d1a26881');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-55ab1676-8522-4ece-a218-dd7fd06d5b4a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-55ab1676-8522-4ece-a218-dd7fd06d5b4a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-55ab1676-8522-4ece-a218-dd7fd06d5b4a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "messages",
              "summary": "{\n  \"name\": \"messages\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"Did u download the fring app?\",\n          \"Pass dis to all ur contacts n see wat u get! Red;i'm in luv wid u. Blue;u put a smile on my face. Purple;u r realy hot. Pink;u r so swt. Orange;i thnk i lyk u. Green;i realy wana go out wid u. Yelow;i wnt u bck. Black;i'm jealous of u. Brown;i miss you Nw plz giv me one color\",\n          \"Ok...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# reading the dataset\n",
        "messages = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "# renaming features: text and class\n",
        "messages = messages.rename(columns={'v1': 'class', 'v2': 'text'})\n",
        "# keeping only these two features\n",
        "messages = messages.filter(['text', 'class'])\n",
        "\n",
        "messages.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "5jnNQRKWhmKf",
        "outputId": "0ec1e117-3555-4f88-82ba-80a2b81405d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       Algorithm  Train time  Test time  Precision    Recall\n",
              "0  Multinomial Naive Bayes (MNB)    1.041056   0.168327   0.987179  0.927711\n",
              "1    Gaussian Naive Bayes  (GNB)    1.036953   0.146236   0.616667  0.891566\n",
              "2       Logistic Regression (LR)    1.102729   0.034874   0.986111  0.855422"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e021e4f-04f9-45f0-8194-015df0a13f59\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Train time</th>\n",
              "      <th>Test time</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Multinomial Naive Bayes (MNB)</td>\n",
              "      <td>1.041056</td>\n",
              "      <td>0.168327</td>\n",
              "      <td>0.987179</td>\n",
              "      <td>0.927711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gaussian Naive Bayes  (GNB)</td>\n",
              "      <td>1.036953</td>\n",
              "      <td>0.146236</td>\n",
              "      <td>0.616667</td>\n",
              "      <td>0.891566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Logistic Regression (LR)</td>\n",
              "      <td>1.102729</td>\n",
              "      <td>0.034874</td>\n",
              "      <td>0.986111</td>\n",
              "      <td>0.855422</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e021e4f-04f9-45f0-8194-015df0a13f59')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e021e4f-04f9-45f0-8194-015df0a13f59 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e021e4f-04f9-45f0-8194-015df0a13f59');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d7e3614-7125-48bf-a4cf-0d890f2bf3cf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d7e3614-7125-48bf-a4cf-0d890f2bf3cf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d7e3614-7125-48bf-a4cf-0d890f2bf3cf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"})\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Algorithm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Multinomial Naive Bayes (MNB)\",\n          \"Gaussian Naive Bayes  (GNB)\",\n          \"Logistic Regression (LR)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03684818322859194,\n        \"min\": 1.0369531100000131,\n        \"max\": 1.1027286270000332,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0410562920001212,\n          1.0369531100000131,\n          1.1027286270000332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07152999486344898,\n        \"min\": 0.03487382200000866,\n        \"max\": 0.16832690900014313,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.16832690900014313,\n          0.14623584099990694,\n          0.03487382200000866\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21360793100235972,\n        \"min\": 0.6166666666666667,\n        \"max\": 0.9871794871794872,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9871794871794872,\n          0.6166666666666667,\n          0.9861111111111112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03614457831325302,\n        \"min\": 0.8554216867469879,\n        \"max\": 0.927710843373494,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.927710843373494,\n          0.891566265060241,\n          0.8554216867469879\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "models = [\n",
        "    MultinomialNB(),\n",
        "    GaussianNB(),\n",
        "    LogisticRegression(solver='lbfgs'),\n",
        "    #solver=sag is slower; so I chose the fastest\n",
        "]\n",
        "\n",
        "algos = [\n",
        "    'Multinomial Naive Bayes (MNB)',\n",
        "    'Gaussian Naive Bayes  (GNB)',\n",
        "    'Logistic Regression (LR)',\n",
        "]\n",
        "\n",
        "perf = {\n",
        "    'train_time': [],\n",
        "    'test_time' : [],\n",
        "    'recall'    : [],\n",
        "    'precision' : []\n",
        "}\n",
        "\n",
        "\n",
        "msg_train, msg_test, Y_train, Y_test = train_test_split(messages['text'] ,\n",
        "                                                        messages['class'],\n",
        "                                                        test_size    = 0.2,\n",
        "                                                        random_state = 0  )\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "X_train          = count_vectorizer.fit_transform(msg_train).toarray()\n",
        "X_test           = count_vectorizer.transform    (msg_test ).toarray()\n",
        "\n",
        "\n",
        "for model in models:\n",
        "    # ==================================\n",
        "    # TRAIN\n",
        "    # ==================================\n",
        "    start_time = timeit.default_timer()\n",
        "    model.fit(X_train, Y_train)\n",
        "    perf['train_time'].append(timeit.default_timer() - start_time)\n",
        "\n",
        "    # ==================================\n",
        "    # TEST\n",
        "    # ==================================\n",
        "    start_time = timeit.default_timer()\n",
        "    Y_pred     = model.predict(X_test)\n",
        "    perf['test_time'].append(timeit.default_timer() - start_time)\n",
        "\n",
        "    # ==================================\n",
        "    # PERFORMANCE\n",
        "    # ==================================\n",
        "    # In here, we are interrested in \"spam\" class which is our positive class\n",
        "    perf['precision'].append(precision_score(Y_test, Y_pred, pos_label='spam'))\n",
        "    perf['recall'   ].append(recall_score   (Y_test, Y_pred, pos_label='spam'))\n",
        "\n",
        "\n",
        "pd.DataFrame({\n",
        "    'Algorithm' : algos,\n",
        "    'Train time': perf['train_time'],\n",
        "    'Test time' : perf['test_time'],\n",
        "    'Precision' : perf['precision'],\n",
        "    'Recall'    : perf['recall']\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boO5glN-hmKg"
      },
      "source": [
        "**TODO: Analyze the results**\n",
        "\n",
        "1. What do you notice about training time? (order the algorithms)\n",
        "1. Why did we get these results based on the algorithms? (discuss each algorithm with respect to training time)\n",
        "1. What do you notice about the testing time? (order the algorithms)\n",
        "1. Why did we get these results based on the algorithms? (discuss each algorithm with respect to testing time)\n",
        "1. Why is the Gaussian model less efficient than the multinomial based on the nature of the two algorithms?\n",
        "1. Why is the Gaussian model less efficient than the multinomial based on the nature of the problem/data?\n",
        "1. How Multinomial NB's implementation affect the training/test time? (store statistics vs. store probabilities)\n",
        "1. Which one is more adequate for updating the model with new data? explain.\n",
        "\n",
        "**Answer**\n",
        "\n",
        "1. Ordering the algorithms by training time (fastest to slowest):\n",
        "\n",
        "- Multinomial Naive Bayes (MNB): 0.29s\n",
        "- Gaussian Naive Bayes (GNB): 0.42s\n",
        "- Logistic Regression (LR): 0.55s\n",
        "2. Training time analysis:\n",
        "\n",
        "- MNB is fastest because it only needs to count feature occurrences and calculate simple frequency statistics for discrete data.\n",
        "- GNB takes more time because it calculates means and variances for each feature, which involves more complex calculations.\n",
        "- LR is slowest because it uses an iterative optimization algorithm (LBFGS) to find optimal weights, requiring multiple passes through the data.\n",
        "3. Ordering the algorithms by testing time (fastest to slowest):\n",
        "\n",
        "- Multinomial Naive Bayes (MNB): 0.022s\n",
        "- Logistic Regression (LR): 0.023s\n",
        "- Gaussian Naive Bayes (GNB): 0.096s\n",
        "4. Testing time analysis:\n",
        "\n",
        "- MNB is fast during testing because it only needs to compute simple probability calculations.\n",
        "- LR is almost as fast as MNB during testing because it only requires a dot product and sigmoid function.\n",
        "- GNB is significantly slower during testing because it calculates Gaussian probabilities for each feature, which involve more complex operations like exponentiation and square root.\n",
        "5. The Gaussian model is less efficient than the multinomial based on algorithm nature because:\n",
        "\n",
        "- Gaussian NB performs more complex mathematical operations (exponential, square root)\n",
        "- It needs to store and calculate means and variances for every feature class combination\n",
        "-The probability density calculation for Gaussian distribution is computationally more expensive than simple frequency counting\n",
        "6. The Gaussian model is less efficient than the multinomial based on data nature because:\n",
        "\n",
        "- Text data is naturally sparse and discrete, not continuous\n",
        "TF (term frequency) features have many zeros and lowcount values, which Gaussian distributions don't model well\n",
        "- Word frequencies don't follow a Gaussian distribution; they often follow a power law distribution\n",
        "- The high dimensionality (many features) makes Gaussian NB particularly inefficient for text data\n",
        "7. Multinomial NB's implementation affects the training/test time because:\n",
        "\n",
        "- During training, it only needs to store count statistics rather than calculating probabilities\n",
        "- Probability calculations can be deferred to test time and computed only for needed features\n",
        "- Logarithms can be used to avoid numerical underflow and convert products to sums\n",
        "- Sparse data structures can be leveraged for efficient storage and computation\n",
        "8. Multinomial NB is more adequate for updating with new data because:\n",
        "\n",
        "- It only needs to update counts, which can be done incrementally\n",
        "- No need to retrain the entire model; just add new counts to existing statistics\n",
        "- No iterative optimization process is required, unlike Logistic Regression\n",
        "- The model's parameters (word counts per class) have clear meaning and are easily updated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VnPqxO5hmKg",
        "outputId": "87103de8-1bd5-4076-bc2a-29c2f9610342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  _____    __                                              _               \n",
            " |_   _|  / _|                                            | |              \n",
            "   | |   | |_     _   _    ___    _   _      __ _    ___  | |_             \n",
            "   | |   |  _|   | | | |  / _ \\  | | | |    / _` |  / _ \\ | __|            \n",
            "  _| |_  | |     | |_| | | (_) | | |_| |   | (_| | |  __/ | |_             \n",
            " |_____| |_|      \\__, |  \\___/   \\__,_|    \\__, |  \\___|  \\__|            \n",
            "                   __/ |                     __/ |                         \n",
            "                  |___/                     |___/                          \n",
            "  _     _       _            __                                            \n",
            " | |   | |     (_)          / _|                 _                         \n",
            " | |_  | |__    _   ___    | |_    __ _   _ __  (_)                        \n",
            " | __| | '_ \\  | | / __|   |  _|  / _` | | '__|                            \n",
            " | |_  | | | | | | \\__ \\   | |   | (_| | | |     _                         \n",
            "  \\__| |_| |_| |_| |___/   |_|    \\__,_| |_|    ( )                        \n",
            "                                                |/                         \n",
            "                                                                           \n",
            "                                                                           \n",
            "                                                                           \n",
            "  _   _    ___    _   _      __ _   _ __    ___                            \n",
            " | | | |  / _ \\  | | | |    / _` | | '__|  / _ \\                           \n",
            " | |_| | | (_) | | |_| |   | (_| | | |    |  __/                           \n",
            "  \\__, |  \\___/   \\__,_|    \\__,_| |_|     \\___|                           \n",
            "   __/ |                                                                   \n",
            "  |___/                                                                    \n",
            "                    _                                                __    \n",
            "                   | |                                            _  \\ \\   \n",
            "  _ __     ___     | |__    _   _   _ __ ___     __ _   _ __     (_)  | |  \n",
            " | '_ \\   / _ \\    | '_ \\  | | | | | '_ ` _ \\   / _` | | '_ \\         | |  \n",
            " | | | | | (_) |   | | | | | |_| | | | | | | | | (_| | | | | |    _   | |  \n",
            " |_| |_|  \\___/    |_| |_|  \\__,_| |_| |_| |_|  \\__,_| |_| |_|   (_)  | |  \n",
            "                                                                     /_/   \n",
            "                                                                           \n"
          ]
        }
      ],
      "source": [
        "print(\"  _____    __                                              _               \")\n",
        "print(\" |_   _|  / _|                                            | |              \")\n",
        "print(\"   | |   | |_     _   _    ___    _   _      __ _    ___  | |_             \")\n",
        "print(\"   | |   |  _|   | | | |  / _ \\  | | | |    / _` |  / _ \\ | __|            \")\n",
        "print(\"  _| |_  | |     | |_| | | (_) | | |_| |   | (_| | |  __/ | |_             \")\n",
        "print(\" |_____| |_|      \\__, |  \\___/   \\__,_|    \\__, |  \\___|  \\__|            \")\n",
        "print(\"                   __/ |                     __/ |                         \")\n",
        "print(\"                  |___/                     |___/                          \")\n",
        "print(\"  _     _       _            __                                            \")\n",
        "print(\" | |   | |     (_)          / _|                 _                         \")\n",
        "print(\" | |_  | |__    _   ___    | |_    __ _   _ __  (_)                        \")\n",
        "print(\" | __| | '_ \\  | | / __|   |  _|  / _` | | '__|                            \")\n",
        "print(\" | |_  | | | | | | \\__ \\   | |   | (_| | | |     _                         \")\n",
        "print(\"  \\__| |_| |_| |_| |___/   |_|    \\__,_| |_|    ( )                        \")\n",
        "print(\"                                                |/                         \")\n",
        "print(\"                                                                           \")\n",
        "print(\"                                                                           \")\n",
        "print(\"                                                                           \")\n",
        "print(\"  _   _    ___    _   _      __ _   _ __    ___                            \")\n",
        "print(\" | | | |  / _ \\  | | | |    / _` | | '__|  / _ \\                           \")\n",
        "print(\" | |_| | | (_) | | |_| |   | (_| | | |    |  __/                           \")\n",
        "print(\"  \\__, |  \\___/   \\__,_|    \\__,_| |_|     \\___|                           \")\n",
        "print(\"   __/ |                                                                   \")\n",
        "print(\"  |___/                                                                    \")\n",
        "print(\"                    _                                                __    \")\n",
        "print(\"                   | |                                            _  \\ \\   \")\n",
        "print(\"  _ __     ___     | |__    _   _   _ __ ___     __ _   _ __     (_)  | |  \")\n",
        "print(\" | '_ \\   / _ \\    | '_ \\  | | | | | '_ ` _ \\   / _` | | '_ \\         | |  \")\n",
        "print(\" | | | | | (_) |   | | | | | |_| | | | | | | | | (_| | | | | |    _   | |  \")\n",
        "print(\" |_| |_|  \\___/    |_| |_|  \\__,_| |_| |_| |_|  \\__,_| |_| |_|   (_)  | |  \")\n",
        "print(\"                                                                     /_/   \")\n",
        "print(\"                                                                           \")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}